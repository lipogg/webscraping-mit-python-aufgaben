{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wichtige Hinweise\n",
    "\n",
    "Bevor ihr diese Aufgabe abgebt stellt sicher, dass alles wie erwartet funktioniert. Befolgt dazu diese Schritte: \n",
    "\n",
    "1. Startet den Kernel neu und führt alle Zellen aus (in der Menüleiste: Run $\\rightarrow$ Restart Kernel and Run All Cells). **Wenn es Fehlermeldungen gibt, behebt diese vor der Abgabe.**  \n",
    "2. Speichert das Notebook (Ctrl + S bzw. Cmd + S oder über File $\\rightarrow$ Save Notebook). Ändert dabei NICHT den Dateinamen.\n",
    "3. Ladet das Notebook herunter (Rechtsklick auf das Notebook $\\rightarrow$ Download).\n",
    "4. Schickt mir das Notebook per Mail an l.poggel@fu-berlin.de. Setzt dabei alle Mitbearbeiter\\:innen in Cc. \n",
    "\n",
    "Achtet auch darauf, alle Stellen auszufüllen, an denen CODE HIER EINGEBEN oder “ANTWORT HIER EINGEBEN” steht, und achtet auf die Hinweise zu den Aufgaben. Bearbeitet die Aufgaben immer genau so, wie es in der Aufgabe steht. Wenn ihr eine Antwort nicht wisst, könnt ihr einfach die entsprechende Zelle leer lassen bzw. die Platzhalter (z.B. `antwort = __`) stehen lassen. **Die leeren Codezellen, die ihr nicht bearbeiten könnt, beinhalten versteckte Tests zur automatisierten Korrektur der Aufgaben. Löscht  diese Zellen nicht und ändert nicht denn Typ der Zelle.** \n",
    "\n",
    "Gebt außerdem die Namen aller Bearbeiter\\:innen an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_1 = \"\"\n",
    "NAME_2 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Übungsaufgaben widmen sich zwei Webseiten, die auf den ersten Blick ähnlich aussehen: https://minimalistbaker.com/recipe-index/ und https://www.airbnb.com/. Der Lerneffekt soll sein, dass ihr lernt einzuschätzen, welche Webscraping-Strategie für verschiedene Webseiten verwendet werden können.\n",
    "\n",
    "## Aufgabe 1: Wiederholung\n",
    "\n",
    "Lest euch nochmal die Inhalte zur Sitzung heute unter dem neuen Kapitel \"Dynamische Webseiten\" auf unserer [Kurs-Website](https://lipogg.github.io/webscraping-mit-python/) durch. Formuliert ein bis drei Fragen zu einem Inhalt, der euch noch nicht ganz klar ist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frage 1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9176e8bffd5edee7bb7b516839bf6b5",
     "grade": true,
     "grade_id": "frage1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "ANTWORT HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frage 2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d9886b31087a621002fb9ce0cac2470",
     "grade": true,
     "grade_id": "frage2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "ANTWORT HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frage 3:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed9f71fca32b42aefee544cc1384e46b",
     "grade": true,
     "grade_id": "frage3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "ANTWORT HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2: Praxis BeautifulSoup\n",
    "\n",
    "1.) Diese Übungsaufgabe widmet sich der Wordpress-Seite https://minimalistbaker.com/. Die Seite habe ich auf der Kurswebsite als Beispiel verwendet. Überprüft zunächst, ob ich euch keinen Quatsch erzählt habe: Gebt die Website-URL auf der Seite https://www.isitwp.com/ ein. Verwendet die Website wirklich WordPress?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42eabc13fe82e9ffe266663a8b1dddbd",
     "grade": true,
     "grade_id": "praxis-1-1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "ANTWORT HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Überprüft als nächstes die robots.txt. Dürft ihr die Seite überhaupt scrapen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6550ca4face7ae04ed4364380613451",
     "grade": true,
     "grade_id": "praxis-1-2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "ANTWORT HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) Ruft die Website https://minimalistbaker.com/ im Chrome-Browser auf. Wenn ihr auf \"All Recipes\" klickt, wird die Seite https://minimalistbaker.com/recipe-index/ aufgerufen. Scrollt zum Seitenende runter, bis ihr die Seitenzahlen seht. Bei https://minimalistbaker.com/recipe-index/ handelt es sich also um die erste von vielen Seiten. Im Folgenden sollt ihr die Namen von allen Rezepten von einer der Seiten extrahieren, und zwar von Seite 2. Was ist die URL zu der Seite? Weist die URL einer Variable mit einem geeigneten Namen zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e3a6ee6dc33b5cf87263c2b71c61930",
     "grade": true,
     "grade_id": "praxis-1-3",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CODE HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.) Überprüft, ob zur Darstellung der Kacheln mit den Rezepten JavaScript verwendet wird. Wie kann man das überprüfen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "083576801caafcf0c221e7be03e32345",
     "grade": true,
     "grade_id": "praxis-1-4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "ANTWORT HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.) Nachdem ihr in Teilaufgabe 4 erfahren habt, dass JavaScript nicht bei der Darstellung der Kacheln mit den Rezepten beteiligt ist, wisst ihr, dass ihr diese Aufgabe wahrscheinlich mit requests und BeautifulSoup lösen könnt. Dazu sollt ihr zunächst ein paar Fragen klären, indem ihr die Webseite und den Quelltext untersucht:\n",
    "\n",
    "- Welche HTML-Elemente werden für die Darstellung der Kacheln mit den verschiedenen Rezepten verwendet?\n",
    "- Sucht im Quellcode der Seite nach der Überschrift \"Epic Vegan Sweet Potato Pie\". Gibt es ein HTML-Element oder vielleicht sogar ein class-Attribut, das addressiert werden kann, um die Namen aller Rezepten auf der Seite zu extrahieren?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9efbc0c0b771aa40a36c14009e6d36b",
     "grade": true,
     "grade_id": "praxis-1-5",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "ANTWORT HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.) Schreibt mit diesem Wissen und mithilfe von BeautifulSoup und requests einen kleinen Web Scraper, der alle Namen von allen Rezepte von der Seite extrahiert. Falls ihr etwas herausgefordert werden wollt, könnt ihr außerdem zu jedem Rezept das Foto extrahieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "854881e021eb528e22bf1d7643da5bf8",
     "grade": true,
     "grade_id": "praxis-1-6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CODE HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3: Praxis Selenium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Diese Übungsaufgabe widmet sich der Website https://www.airbnb.com/. Überprüft als erstes die robots.txt. Dürft ihr die Seite überhaupt scrapen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f48fc4c24735c0cd7760c5cb6ef4b8c6",
     "grade": true,
     "grade_id": "praxis-2-1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "ANTWORT HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Ruft die Website https://www.airbnb.com/ im Chrome-Browser auf. Im Folgenden sollt ihr die Ortsangaben zu den Unterkünften, die auf der Startseite https://www.airbnb.com/ angezeigt werden, scrapen. Scrollt zunächst runter bis zum Seitenende. Klickt auf \"Show more\" und scroll anschließend wieder bis zum Seitenende. Ihr bemerkt: Die Seite verwendet \"infinite scrolling\", sodass es kein festgelegtes Seitenende gibt. Das ist bereits ein Hinweis darauf, dass die Seite JavaScript zur Darstellung der Inhalte verwendet. Überprüft anschließend mithilfe der Browser-Entwicklertools: Wird zur Darstellung der Kacheln mit den Unterkünften tatsächlich JavaScript verwendet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce04e7707fbb85520314f4ed8b2ce19b",
     "grade": true,
     "grade_id": "praxis-2-2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "ANTWORT HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) Nachdem ihr in Teilaufgabe 2 erfahren habt, dass JavaScript bei der Darstellung der Kacheln mit den Unterkünften beteiligt ist, wisst ihr, dass ihr diese Aufgabe nicht mit requests und BeautifulSoup lösen könnt. Stattdessen werdet ihr Selenium verwenden. Dazu sollt ihr zunächst ein paar Fragen klären, indem ihr die Webseite und den Quellcode untersucht:\n",
    "\n",
    "- Welche HTML-Elemente werden für die Darstellung der Kacheln mit den verschiedenen Unterkünften verwendet?\n",
    "- Sucht im Quellcode der Seite nach der Überschrift der ersten Kachel. Gibt es ein HTML-Element oder vielleicht sogar ein class-Attribut, das addressiert werden kann, um die Orte aller Unterkünfte auf der Seite zu extrahieren?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6670760ccd043361327946531e93edf4",
     "grade": true,
     "grade_id": "praxis-2-3",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "ANTWORT HIER EINGEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.) Schreibt mit diesem Wissen und mithilfe von Selenium und dem Chrome WebDriver einen kleinen Web Scraper, der alle Ortsangaben zu allen Unterkünften von der Seite extrahiert. Dabei könnt ihr grundsätzlich so vorgehen, wie im Beispiel auf der Kurswebsite, aber ihr müsst folgendes beachten:\n",
    "\n",
    "- Bei der Suche mithilfe von CSS-Selektoren (also mithilfe der class-Attribute) müsst ihr Leerzeichen durch einen Punkt ersetzen, falls der CSS-Selektor ein Leerzeichen enthält. Also zum Beispiel müsstet ihr \"g1qv1ctd c1v0rf5q dir dir-ltr\" ändern zu \"g1qv1ctd.c1v0rf5q.dir.dir-ltr\".\n",
    "- Nachdem ihr die HTTP-Anfrage gestellt habt, müsst ihr ein paar Sekunden warten, damit der Browser genug Zeit hat, die Inhalte zu rendern. Eine automatische Wartezeit könnt ihr einstellen mit time.sleep(5). Dazu müsst ihr zunächst wieder das Modul time importieren. In der nächsten Woche lernt ihr eine bessere Methode kennen, um in Selenium auf das Laden von Inhalten zu warten. \n",
    "- Da die Seite infinite scrolling verwendet, findet euer Web Scraper nur eine begrenzte Anzahl an Elementen. Um mehr Elemente zu finden, muss das Scrollen im Browser simuliert werden. Das müsst ihr aber noch nicht umsetzen; das lernen wir nächste Stunde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57a7daaf622fb281df3408c09552620e",
     "grade": true,
     "grade_id": "praxis-2-4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CODE HIER EINGEBEN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
